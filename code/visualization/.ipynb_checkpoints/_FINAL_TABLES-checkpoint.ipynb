{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9fd8c359-e7fe-438d-a1e8-b4a455cb8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b190af-5469-4595-9110-02beb9014ef0",
   "metadata": {},
   "source": [
    "### Merge meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "da0421ac-9055-4287-af4b-5813e5d3ccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.1 ms, sys: 29.2 ms, total: 123 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# = = = = = = = = = = \n",
    "# Load dataframe\n",
    "# = = = = = = = = = = \n",
    "read_manually = True\n",
    "subset_to_10k = False\n",
    "\n",
    "if read_manually:\n",
    "    # path to BLEU etc.\n",
    "    p = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/database/FINAL_FINAL_meta_and_metrics_only.csv')\n",
    "    \n",
    "    # exclude text-columns (not necessary, already loading DF without text columns `meta_and_metrics_only`\n",
    "    #headers = [*pd.read_csv(p, sep='|', nrows=1)]\n",
    "    #df = pd.read_csv(p, sep='|', usecols=[c for c in headers if c not in {'html', 'nougat', 'pymupdf', 'grobid', 'pypdf', 'marker', 'tesseract'}])\n",
    "\n",
    "    # load\n",
    "    df = pd.read_csv(p, sep='|')\n",
    "\n",
    "    # load subset indices (10_240)\n",
    "    if subset_to_10k:\n",
    "        df_10240 = pd.read_csv('/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/database/scaling_data/frames/df_orig_10240.csv', sep='|')\n",
    "        \n",
    "        # subset\n",
    "        df_subset = df[df['path'].isin(df_10240['path'])]\n",
    "        df = df_subset.copy()\n",
    "else:\n",
    "    df = pd.read_csv('./frames/meta_frame.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "134c8c51-7041-4fa9-b90f-9d54686b10a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23398"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c97e9bc2-4559-4102-89dc-a885f5cec608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completion rate</th>\n",
       "      <th>bleu_median</th>\n",
       "      <th>bleu_iqr</th>\n",
       "      <th>car_median</th>\n",
       "      <th>car_iqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nougat</th>\n",
       "      <td>95.11</td>\n",
       "      <td>47.42</td>\n",
       "      <td>20.96</td>\n",
       "      <td>66.59</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marker</th>\n",
       "      <td>90.67</td>\n",
       "      <td>51.28</td>\n",
       "      <td>20.09</td>\n",
       "      <td>65.86</td>\n",
       "      <td>20.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grobid</th>\n",
       "      <td>77.31</td>\n",
       "      <td>29.43</td>\n",
       "      <td>20.60</td>\n",
       "      <td>56.73</td>\n",
       "      <td>15.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tesseract</th>\n",
       "      <td>96.37</td>\n",
       "      <td>47.62</td>\n",
       "      <td>17.30</td>\n",
       "      <td>65.64</td>\n",
       "      <td>15.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pymupdf</th>\n",
       "      <td>90.15</td>\n",
       "      <td>50.14</td>\n",
       "      <td>21.24</td>\n",
       "      <td>64.01</td>\n",
       "      <td>23.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pypdf</th>\n",
       "      <td>85.75</td>\n",
       "      <td>44.09</td>\n",
       "      <td>21.09</td>\n",
       "      <td>40.92</td>\n",
       "      <td>24.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Completion rate  bleu_median  bleu_iqr  car_median  car_iqr\n",
       "nougat               95.11        47.42     20.96       66.59    16.88\n",
       "marker               90.67        51.28     20.09       65.86    20.72\n",
       "grobid               77.31        29.43     20.60       56.73    15.78\n",
       "tesseract            96.37        47.62     17.30       65.64    15.37\n",
       "pymupdf              90.15        50.14     21.24       64.01    23.19\n",
       "pypdf                85.75        44.09     21.09       40.92    24.11"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_flag = False\n",
    "median_flag = True\n",
    "threshold = 0.1\n",
    "\n",
    "# encode how parser names are written\n",
    "name_dict = {'nougat' : 'Nougat', 'pymupdf' : 'PyMuPDF', 'grobid' : 'GROBID', 'marker' : 'Marker', \n",
    "             'tesseract' : 'Tesseract', 'pypdf' : 'pypdf'}\n",
    "score_types = ['bleu', 'rouge', 'car']\n",
    "\n",
    "def compute_iqr(column: pd.Series) -> float:\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    return Q3 - Q1\n",
    "    \n",
    "# encode how parser names are written\n",
    "name_dict = {'nougat' : 'Nougat', 'pymupdf' : 'PyMuPDF', 'grobid' : 'GROBID', 'marker' : 'Marker', \n",
    "             'tesseract' : 'Tesseract', 'pypdf' : 'pypdf'}\n",
    "score_types = ['bleu', 'rouge', 'car']\n",
    "\n",
    "# Lists for BLEU, ROUGE, and CAR columns\n",
    "norm_str = '_norm' if normalized_flag else ''\n",
    "score_list_dict = {}\n",
    "for score in score_types:\n",
    "    score_list = []\n",
    "    for parser in name_dict.keys():\n",
    "        element = f'{score}_{parser}{norm_str}'\n",
    "        score_list.append(element)\n",
    "    score_list_dict[score] = score_list\n",
    "\n",
    "# Parsers (row indices)\n",
    "parsers = name_dict.keys()\n",
    "\n",
    "if median_flag:\n",
    "    # Compute success rate\n",
    "    score_columns = score_list_dict['bleu']  # Assuming you want to use 'bleu' scores for success rate\n",
    "    colnames = [name_dict[c.split('_')[1]] for c in score_columns]\n",
    "    bomb_frequencies = (df[score_columns] < threshold).mean()\n",
    "    success_rate = {c: 1.0 - f for c, f in zip(colnames, bomb_frequencies)}\n",
    "    \n",
    "    # Create empty dictionaries to store median and IQR results\n",
    "    median_dict = {}\n",
    "    iqr_dict = {}\n",
    "    \n",
    "    # Compute median and IQR for each score type and parser\n",
    "    for score_type in score_types:\n",
    "        score_columns = score_list_dict[score_type]\n",
    "        for parser, col in zip(parsers, score_columns):\n",
    "            # Compute median and IQR for the current column\n",
    "            #median_value = df[col].median()\n",
    "            #iqr_value = compute_iqr(df[col])\n",
    "            # Compute conditional mean (for values > 0.05)\n",
    "            filtered_values = df[col][df[col] > threshold]\n",
    "            median_value = filtered_values.median() if not filtered_values.empty else 0.0\n",
    "            iqr_value = compute_iqr(filtered_values) if not filtered_values.empty else 0.0\n",
    "            \n",
    "            # Store results in the dictionaries\n",
    "            median_dict[f'{score_type}_median'] = median_dict.get(f'{score_type}_median', []) + [median_value]\n",
    "            iqr_dict[f'{score_type}_iqr'] = iqr_dict.get(f'{score_type}_iqr', []) + [iqr_value]\n",
    "    \n",
    "    # Combine success rate, median, and IQR into a DataFrame with parsers as row indices\n",
    "    df_overview = pd.DataFrame({\n",
    "        'Completion rate': [success_rate[name_dict[p]] for p in parsers],\n",
    "        'bleu_median': median_dict['bleu_median'],\n",
    "        'bleu_iqr': iqr_dict['bleu_iqr'],\n",
    "        'car_median': median_dict['car_median'],\n",
    "        'car_iqr': iqr_dict['car_iqr']\n",
    "    }, index=parsers)\n",
    "else:\n",
    "    # Compute success rate\n",
    "    score_columns = score_list_dict['bleu']  # Assuming you want to use 'bleu' scores for success rate\n",
    "    colnames = [name_dict[c.split('_')[1]] for c in score_columns]\n",
    "    bomb_frequencies = (df[score_columns] < threshold).mean()\n",
    "    success_rate = {c: 1.0 - f for c, f in zip(colnames, bomb_frequencies)}\n",
    "    \n",
    "    # Create empty dictionaries to store conditional mean and standard deviation results\n",
    "    mean_dict = {}\n",
    "    std_dict = {}\n",
    "    \n",
    "    # Compute conditional mean and standard deviation for each score type and parser\n",
    "    for score_type in score_types:\n",
    "        score_columns = score_list_dict[score_type]\n",
    "        for parser, col in zip(parsers, score_columns):\n",
    "            # Compute conditional mean (for values > 0.05)\n",
    "            filtered_values = df[col][df[col] > threshold]\n",
    "            mean_value = filtered_values.mean() if not filtered_values.empty else 0.0\n",
    "            std_value = filtered_values.std() if not filtered_values.empty else 0.0\n",
    "            \n",
    "            # Store results in the dictionaries\n",
    "            mean_dict[f'{score_type}_mean'] = mean_dict.get(f'{score_type}_mean', []) + [mean_value]\n",
    "            std_dict[f'{score_type}_std'] = std_dict.get(f'{score_type}_std', []) + [std_value]\n",
    "    \n",
    "    # Combine success rate, conditional mean, and standard deviation into a DataFrame with parsers as row indices\n",
    "    df_overview = pd.DataFrame({\n",
    "        'Completion rate': [success_rate[name_dict[p]] for p in parsers],\n",
    "        'bleu_mean': mean_dict['bleu_mean'],\n",
    "        'bleu_std': std_dict['bleu_std'],\n",
    "        'car_mean': mean_dict['car_mean'],\n",
    "        'car_std': std_dict['car_std']\n",
    "    }, index=parsers)\n",
    "    \n",
    "    # Reorder parsers as per parsers_order\n",
    "    parsers_order = ['nougat',  'marker',  'grobid', 'tesseract', 'pymupdf', 'pypdf']\n",
    "    df_overview = df_overview.reindex(parsers_order)\n",
    "\n",
    "# parer order\n",
    "parsers_order = ['nougat',  'marker',  'grobid', 'tesseract', 'pymupdf', 'pypdf']\n",
    "df_overview = df_overview.reindex(parsers_order)\n",
    "\n",
    "(df_overview*100.).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c0b9e750-2e43-4e79-a9d6-4e8057c8142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{table}[htbp]\n",
      "    \\caption{Accuracy: Document- (completion rate), word- (BLEU), and character-level accuracy}\n",
      "    \\begin{center}\n",
      "    \\begin{tabular}{|c|c|c|c|c|c|}\n",
      "    \\hline\n",
      "    \\textbf{Parser} & \\textbf{Completion [\\%]} & \\multicolumn{2}{|c|}{\\textbf{BLEU [\\%]}} & \\multicolumn{2}{|c|}{\\textbf{CAR [\\%]}} \\\\\n",
      "    \\cline{3-6}\n",
      "     &  & \\textbf{Median} & \\textbf{IQR} & \\textbf{Median} & \\textbf{IQR} \\\\\n",
      "    \\hline\n",
      "    Nougat & 95.1 & 47.4 & 21.0 & \\textbf{66.6} & 16.9 \\\\ \n",
      "\\hline\n",
      "Marker & 90.7 & \\textbf{51.3} & 20.1 & 65.9 & 20.7 \\\\ \n",
      "\\hline\n",
      "Grobid & 77.3 & 29.4 & 20.6 & 56.7 & 15.8 \\\\ \n",
      "\\hline\n",
      "Tesseract & \\textbf{96.4} & 47.6 & \\textbf{17.3} & 65.6 & \\textbf{15.4} \\\\ \n",
      "\\hline\n",
      "Pymupdf & 90.2 & 50.1 & 21.2 & 64.0 & 23.2 \\\\ \n",
      "\\hline\n",
      "Pypdf & 85.7 & 44.1 & 21.1 & 40.9 & 24.1 \\\\ \n",
      "\\hline\n",
      "\n",
      "    \\end{tabular}\n",
      "    \\label{tab1}\n",
      "    \\end{center}\n",
      "    \\end{table}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_with_highlights(df: pd.DataFrame, median_flag: bool):\n",
    "    # Multiply all values by 100 and round to one decimal place\n",
    "    df = df * 100.0\n",
    "    df = df.round(1)\n",
    "\n",
    "    if median_flag:\n",
    "        # Identify maximum and minimum values for highlighting\n",
    "        max_completion_rate = df['Completion rate'].max()\n",
    "        max_bleu_median = df['bleu_median'].max()\n",
    "        max_car_median = df['car_median'].max()\n",
    "        \n",
    "        min_bleu_iqr = df['bleu_iqr'].min()\n",
    "        min_car_iqr = df['car_iqr'].min()\n",
    "        \n",
    "        # Start writing LaTeX table\n",
    "        latex_str = r\"\"\"\n",
    "    \\begin{table}[htbp]\n",
    "    \\caption{Accuracy: Document- (coverage rate), word- (BLEU), and character-level accuracy}\n",
    "    \\begin{center}\n",
    "    \\begin{tabular}{|c|c|c|c|c|c|}\n",
    "    \\hline\n",
    "    \\textbf{Parser} & \\textbf{Coverage [\\%]} & \\multicolumn{2}{|c|}{\\textbf{BLEU [\\%]}} & \\multicolumn{2}{|c|}{\\textbf{CAR [\\%]}} \\\\\n",
    "    \\cline{3-6}\n",
    "     &  & \\textbf{Median} & \\textbf{IQR} & \\textbf{Median} & \\textbf{IQR} \\\\\n",
    "    \\hline\n",
    "    \"\"\"\n",
    "    \n",
    "        # Iterate through the rows and format each line in LaTeX\n",
    "        for index, row in df.iterrows():\n",
    "            # Format completion rate\n",
    "            completion_rate = f\"\\\\textbf{{{row['Completion rate']:.1f}}}\" if row['Completion rate'] == max_completion_rate else f\"{row['Completion rate']:.1f}\"\n",
    "            \n",
    "            # Format BLEU median and IQR\n",
    "            bleu_median = f\"\\\\textbf{{{row['bleu_median']:.1f}}}\" if row['bleu_median'] == max_bleu_median else f\"{row['bleu_median']:.1f}\"\n",
    "            bleu_iqr = f\"\\\\textbf{{{row['bleu_iqr']:.1f}}}\" if row['bleu_iqr'] == min_bleu_iqr else f\"{row['bleu_iqr']:.1f}\"\n",
    "            \n",
    "            # Format CAR median and IQR\n",
    "            car_median = f\"\\\\textbf{{{row['car_median']:.1f}}}\" if row['car_median'] == max_car_median else f\"{row['car_median']:.1f}\"\n",
    "            car_iqr = f\"\\\\textbf{{{row['car_iqr']:.1f}}}\" if row['car_iqr'] == min_car_iqr else f\"{row['car_iqr']:.1f}\"\n",
    "            \n",
    "            # Add the formatted row to the LaTeX string\n",
    "            latex_str += f\"{index.capitalize()} & {completion_rate} & {bleu_median} & {bleu_iqr} & {car_median} & {car_iqr} \\\\\\\\ \\n\"\n",
    "            latex_str += r\"\\hline\" + \"\\n\"\n",
    "    \n",
    "        # Closing the table structure\n",
    "        latex_str += r\"\"\"\n",
    "    \\end{tabular}\n",
    "    \\label{tab1}\n",
    "    \\end{center}\n",
    "    \\end{table}\n",
    "    \"\"\"\n",
    "    \n",
    "    else:\n",
    "        # Identify maximum and minimum values for highlighting mean/std\n",
    "        max_completion_rate = df['Completion rate'].max()\n",
    "        max_bleu_mean = df['bleu_mean'].max()\n",
    "        max_car_mean = df['car_mean'].max()\n",
    "        \n",
    "        min_bleu_std = df['bleu_std'].min()\n",
    "        min_car_std = df['car_std'].min()\n",
    "        \n",
    "        # Start writing LaTeX table\n",
    "        latex_str = r\"\"\"\n",
    "    \\begin{table}[htbp]\n",
    "    \\caption{Accuracy: Document- (coverage rate), word- (BLEU), and character-level accuracy (mean)}\n",
    "    \\begin{center}\n",
    "    \\begin{tabular}{|c|c|c|c|c|c|}\n",
    "    \\hline\n",
    "    \\textbf{Parser} & \\textbf{Coverage [\\%]} & \\multicolumn{2}{|c|}{\\textbf{BLEU [\\%]}} & \\multicolumn{2}{|c|}{\\textbf{CAR [\\%]}} \\\\\n",
    "    \\cline{3-6}\n",
    "     &  & \\textbf{Mean} & \\textbf{Std} & \\textbf{Mean} & \\textbf{Std} \\\\\n",
    "    \\hline\n",
    "    \"\"\"\n",
    "    \n",
    "        # Iterate through the rows and format each line in LaTeX\n",
    "        for index, row in df.iterrows():\n",
    "            # Format completion rate\n",
    "            completion_rate = f\"\\\\textbf{{{row['Completion rate']:.1f}}}\" if row['Completion rate'] == max_completion_rate else f\"{row['Completion rate']:.1f}\"\n",
    "            \n",
    "            # Format BLEU mean and std\n",
    "            bleu_mean = f\"\\\\textbf{{{row['bleu_mean']:.1f}}}\" if row['bleu_mean'] == max_bleu_mean else f\"{row['bleu_mean']:.1f}\"\n",
    "            bleu_std = f\"\\\\textbf{{{row['bleu_std']:.1f}}}\" if row['bleu_std'] == min_bleu_std else f\"{row['bleu_std']:.1f}\"\n",
    "            \n",
    "            # Format CAR mean and std\n",
    "            car_mean = f\"\\\\textbf{{{row['car_mean']:.1f}}}\" if row['car_mean'] == max_car_mean else f\"{row['car_mean']:.1f}\"\n",
    "            car_std = f\"\\\\textbf{{{row['car_std']:.1f}}}\" if row['car_std'] == min_car_std else f\"{row['car_std']:.1f}\"\n",
    "            \n",
    "            # Add the formatted row to the LaTeX string\n",
    "            latex_str += f\"{index.capitalize()} & {completion_rate} & {bleu_mean} & {bleu_std} & {car_mean} & {car_std} \\\\\\\\ \\n\"\n",
    "            latex_str += r\"\\hline\" + \"\\n\"\n",
    "    \n",
    "        # Closing the table structure\n",
    "        latex_str += r\"\"\"\n",
    "    \\end{tabular}\n",
    "    \\label{tab1}\n",
    "    \\end{center}\n",
    "    \\end{table}\n",
    "    \"\"\"\n",
    "    \n",
    "    return latex_str\n",
    "\n",
    "# Example usage\n",
    "# Assuming df_overview is the DataFrame you showed earlier\n",
    "# Pass 'median_flag=True' for median/IQR table, 'median_flag=False' for mean/std table\n",
    "latex_code = generate_latex_table_with_highlights(df_overview, median_flag=median_flag)\n",
    "print(latex_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fffb7c52-f6fb-4760-b9a6-2a67ecd61ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'bleu_nougat', 'rouge_nougat', 'car_nougat', 'bleu_nougat_norm',\n",
       "       'rouge_nougat_norm', 'car_nougat_norm', 'bleu_pymupdf', 'rouge_pymupdf',\n",
       "       'car_pymupdf', 'bleu_pymupdf_norm', 'rouge_pymupdf_norm',\n",
       "       'car_pymupdf_norm', 'bleu_grobid', 'rouge_grobid', 'car_grobid',\n",
       "       'bleu_grobid_norm', 'rouge_grobid_norm', 'car_grobid_norm',\n",
       "       'bleu_marker', 'rouge_marker', 'car_marker', 'bleu_marker_norm',\n",
       "       'rouge_marker_norm', 'car_marker_norm', 'bleu_tesseract',\n",
       "       'rouge_tesseract', 'car_tesseract', 'bleu_tesseract_norm',\n",
       "       'rouge_tesseract_norm', 'car_tesseract_norm', 'bleu_pypdf',\n",
       "       'rouge_pypdf', 'car_pypdf', 'bleu_pypdf_norm', 'rouge_pypdf_norm',\n",
       "       'car_pypdf_norm', 'category', 'subcategory'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8243a72d-b0a0-4d63-be99-c71c9dc491fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completion rate</th>\n",
       "      <th>bleu_median</th>\n",
       "      <th>bleu_iqr</th>\n",
       "      <th>car_median</th>\n",
       "      <th>car_iqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nougat</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.462310</td>\n",
       "      <td>0.300216</td>\n",
       "      <td>0.661556</td>\n",
       "      <td>0.222016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pymupdf</th>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.498479</td>\n",
       "      <td>0.354954</td>\n",
       "      <td>0.654622</td>\n",
       "      <td>0.297272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grobid</th>\n",
       "      <td>0.825195</td>\n",
       "      <td>0.223779</td>\n",
       "      <td>0.259463</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>0.192155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marker</th>\n",
       "      <td>0.919922</td>\n",
       "      <td>0.495679</td>\n",
       "      <td>0.347011</td>\n",
       "      <td>0.648923</td>\n",
       "      <td>0.329011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tesseract</th>\n",
       "      <td>0.982910</td>\n",
       "      <td>0.470957</td>\n",
       "      <td>0.224311</td>\n",
       "      <td>0.670663</td>\n",
       "      <td>0.191685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pypdf</th>\n",
       "      <td>0.929102</td>\n",
       "      <td>0.416638</td>\n",
       "      <td>0.331006</td>\n",
       "      <td>0.349962</td>\n",
       "      <td>0.246086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Completion rate  bleu_median  bleu_iqr  car_median   car_iqr\n",
       "nougat            0.975000     0.462310  0.300216    0.661556  0.222016\n",
       "pymupdf           0.945312     0.498479  0.354954    0.654622  0.297272\n",
       "grobid            0.825195     0.223779  0.259463    0.542560  0.192155\n",
       "marker            0.919922     0.495679  0.347011    0.648923  0.329011\n",
       "tesseract         0.982910     0.470957  0.224311    0.670663  0.191685\n",
       "pypdf             0.929102     0.416638  0.331006    0.349962  0.246086"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a74540-9020-459c-ab92-a9c9a3b80b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Failure Rate' : bomb_frequencies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6aa8e-2771-49e8-9923-5e557cc7d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_prop.set_size(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99526a-3c97-4534-94e2-d136e30e106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_means = []\n",
    "for col in score_columns:\n",
    "    cond_means.append(float(df[col].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb9493-4d88-4564-be09-a354250ab090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de362c-2c37-4134-876a-449d97784e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
