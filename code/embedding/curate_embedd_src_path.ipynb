{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6b53cf7-10bf-4dd7-bb30-e89057608fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1dacc-04ff-4d57-b69c-6d5ffb723565",
   "metadata": {},
   "source": [
    "## Analyze predictability of text-based embedding\n",
    "Dimensions to consider (in order of significance)\n",
    "\n",
    "\n",
    "## $\\rightarrow$ Data level\n",
    "Create directory structure that allows easy \"switch out\" for subsequent model training and analysis scripts.\n",
    "Mine `.jsonl` files and write into target directory with searchable subdir structure.\n",
    "\n",
    "#### 1. Response `y`\n",
    "What variable are we trying to predict? Let's fix `BLEU` or `ROUGE`.\n",
    "Will be mined from a CSV such as `../database/parser_output_with_scores.csv`\n",
    "Later human-aligned.\n",
    "\n",
    "#### 2. Source of text\n",
    "What parser yields text (and, hence, embeddings) that reliably predicts accuracy? How does it compare to the goldlabel `html`?\n",
    "[`html`, `pymupdf`, `nougat`, `marker`, `grobid`]`\n",
    "\n",
    "#### 3. How much text is required?\n",
    "First page? Half of that, double of that? Single (first) page in PyMupDF amounts to ~3200 characters\n",
    "[`1600`, `3200`, `6400`, `9600`, `12800`]`\n",
    "\n",
    "2. and 3. be determined when embedding script is executed (in this directory) `curate_jonls_for_embeddings.py`\n",
    "\n",
    "#### 4. What is the train/test/val split?\n",
    "Respect validation-only journals (e.g. Nature) and sample stratified over rest. Curate `../database/pdf_meta_table.csv`\n",
    "\n",
    "## $\\rightarrow$ Embedder Model\n",
    "Will be determined when embedding script is executed (in this directory) `curate_jonls_for_embeddings.py`\n",
    "\n",
    "#### 5. What model does the embedding?\n",
    "Three models of slightly varying type shoudl be exhaustive: \n",
    "\n",
    "- `GIST-Embedding-v0` : tiny LLM\n",
    "- `stella_en_400M_v5` : small, very good retrieval performance (HF MTEB leaderboard) yet <500M + good downstream classification\n",
    "- `Salesforce/SFR-Embedding-2_R` : large-ish (7B), downstream text-classification\n",
    "\n",
    "#### 6. Quantization level?\n",
    "How much quantization can be applied?\n",
    "\n",
    "## $\\rightarrow$ Inference Model\n",
    "\n",
    "#### 7. Simple regression model\n",
    "Whatever works (trains fast, simple inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c36b700d-3dd8-473a-878b-cfb277511926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source directory\n",
    "p_src = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/joint_to_pymupdf/parsed_pdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8112f564-ca60-4057-a3c0-8bc7c390c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load jsonls\n",
    "first_pages = []\n",
    "jsonl_file_paths = [p_src / f for f in os.listdir(p_src) if Path(f).suffix=='.jsonl']\n",
    "for jsonl_file_p in jsonl_file_paths:\n",
    "    with open(jsonl_file_p, 'r') as doc:\n",
    "        for line in doc:\n",
    "            # open file\n",
    "            data = json.loads(line)\n",
    "\n",
    "            # first page\n",
    "            first_page = data['metadata']['first_page']\n",
    "\n",
    "            first_pages.append(first_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae4d2c98-a819-4e6a-882c-cd9eb08a87a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24980"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c5cf979-4d1d-42ef-94b4-ac74a83a2c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of #chars on first page (PyMuPDF)\n",
      "mean \t: 3227.2\n",
      "median \t: 3115.0\n",
      "std \t: 1599.5\n"
     ]
    }
   ],
   "source": [
    "# Mean, Median, standard deviation of number of characters on first page (PyMuPDF)\n",
    "char_len_pymupdf_first_pages_list = [len(f) for f in first_pages]\n",
    "\n",
    "# plot\n",
    "print('Summary statistics of #chars on first page (PyMuPDF)')\n",
    "for func in [np.mean, np.median, np.std]:\n",
    "    print(f\"{str(func).split(' ')[1]} \\t: {float(func(char_len_pymupdf_first_pages_list)):.1f}\")\n",
    "\n",
    "# Derive\n",
    "1600, 3200, 4800, 6400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb1cf828-7ef5-488e-b7ad-3feb043eb732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'std'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6116603-3812-49cc-9962-f9adeb992dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target dir\n",
    "p = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/embedd_source/pymupdf_p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d626a9-024d-4d3f-986d-66642a58f0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
