{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "39d23175-a9da-4d41-a2e6-780e0f74a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16252afd-ef55-45cd-a340-9be01f83ca89",
   "metadata": {},
   "source": [
    "## Assemble Dataset\n",
    "\n",
    "# (!) Crucial. Include all test-examples\n",
    "\n",
    "#### `1536` 256 * 6 (256 per Publisher)\n",
    "50% (768 = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7a1558e2-090e-4da4-a599-48337c4193e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load split\n",
    "with open('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/split_official/pymupdf.yaml', 'r') as f:\n",
    "    subsets = yaml.safe_load(f)\n",
    "\n",
    "path_to_subset = {}\n",
    "\n",
    "# `path` : subset\n",
    "for key, value_list in subsets.items():\n",
    "    for item in value_list:\n",
    "        path_to_subset[item] = key  # Assign the key to each element in the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5c1baf43-9d8e-44b6-a0bc-a1cdb252f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_1536_flag = False # 2nd October\n",
    "\n",
    "# 1536 dataset\n",
    "df_categories_final = pd.read_csv('./final_predicted_meta/predicted_categories_final.csv', sep='|')\n",
    "\n",
    "# add subset\n",
    "df_categories_final['subset'] = df_categories_final['path'].map(path_to_subset)\n",
    "df_categories_final = df_categories_final[~(df_categories_final['subset'].isna())]\n",
    "\n",
    "# Initialize an empty list to store the sampled subframes\n",
    "sampled_subframes = []\n",
    "\n",
    "seedVal = 316484 # ensures no duplicates\n",
    "test_ratio = 0.5\n",
    "# Group by 'publisher' and sample 200 rows per group, favoring 'test' in 'subset'\n",
    "for path_value, group in df_categories_final.groupby('publisher'):\n",
    "    if len(group) >= 256:\n",
    "        # Separate 'test' rows and other rows\n",
    "        test_group = group[group['subset'] == 'test']\n",
    "        other_group = group[group['subset'] != 'test']\n",
    "\n",
    "        # Calculate how many 'test' and 'other' rows to sample based on the ratio\n",
    "        n_test = min(int(256 * test_ratio), len(test_group))\n",
    "        n_other = 256 - n_test\n",
    "\n",
    "        # Sample 'test' rows and 'other' rows\n",
    "        sampled_test = test_group.sample(n=n_test, random_state=seedVal)\n",
    "        sampled_other = other_group.sample(n=n_other, random_state=seedVal) if len(other_group) > 0 else pd.DataFrame()\n",
    "\n",
    "        # Concatenate the two sampled subframes and append to the list\n",
    "        sampled_subframes.append(pd.concat([sampled_test, sampled_other]))\n",
    "    else:\n",
    "        # If less than 256 rows in the group, append all rows\n",
    "        sampled_subframes.append(group)\n",
    "\n",
    "# Concatenate all sampled subframes row-wise into one DataFrame\n",
    "df_sampled = pd.concat(sampled_subframes, axis=0, ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "freq, counts = np.unique(df_sampled['class'], return_counts=True)\n",
    "\n",
    "# store\n",
    "if save_1536_flag:\n",
    "    df_sampled.to_csv('./testset_1536/df_1536.csv', sep='|', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "46ada8ff-4506-4650-b4f8-da52c2ab6a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array(['Nature', 'arxiv', 'biorxiv', 'bmc', 'mdpi', 'medrxiv'],\n",
       "        dtype=object),\n",
       "  array([256, 256, 256, 256, 256, 256])),\n",
       " 1536,\n",
       " (array(['test', 'train', 'val'], dtype=object), array([768, 501, 267])))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_sampled['publisher'], return_counts=True), len(set(df_sampled['path'])), np.unique(df_sampled['subset'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a66e55-e3a2-4477-ba75-514422d8282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_sampled['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7c73c-5be5-4791-aac3-c890d7e4afff",
   "metadata": {},
   "source": [
    "## 10_000 papers\n",
    "\n",
    "### split\n",
    "test: `35%`, val: `11%` (as much as possible)\n",
    "\n",
    "### publishers\n",
    "Nature: `9.3%`, MedRXiv : `14.1%`, MDPI: `16%`,  all others: `20.2%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "01d9549f-4ab2-45a9-b7f6-0046f7cf2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10000 \n",
    "\n",
    "save_10k_flag = False # 2nd october\n",
    "\n",
    "# 10_000 dataset\n",
    "df_categories_final = pd.read_csv('./final_predicted_meta/predicted_categories_final.csv', sep='|')\n",
    "\n",
    "# ubset\n",
    "df_categories_final['subset'] = df_categories_final['path'].map(path_to_subset)\n",
    "df_categories_final = df_categories_final[~(df_categories_final['subset'].isna())]\n",
    "\n",
    "# Initialize an empty list to store the sampled subframes\n",
    "sampled_subframes = []\n",
    "\n",
    "seedVal = 316484 # ensures no duplicates\n",
    "test_ratio = 0.59\n",
    "k = 2068\n",
    "# Group by 'publisher' and sample 200 rows per group, favoring 'test' in 'subset'\n",
    "for path_value, group in df_categories_final.groupby('publisher'):\n",
    "    if len(group) >= k:\n",
    "        # Separate 'test' rows and other rows\n",
    "        test_group = group[group['subset'] == 'test']\n",
    "        other_group = group[group['subset'] != 'test']\n",
    "\n",
    "        # Calculate how many 'test' and 'other' rows to sample based on the ratio\n",
    "        n_test = min(int(k * test_ratio), len(test_group))\n",
    "        n_other = k - n_test\n",
    "\n",
    "        # Sample 'test' rows and 'other' rows\n",
    "        sampled_test = test_group.sample(n=n_test, random_state=seedVal)\n",
    "        sampled_other = other_group.sample(n=n_other, random_state=seedVal) if len(other_group) > 0 else pd.DataFrame()\n",
    "\n",
    "        # Concatenate the two sampled subframes and append to the list\n",
    "        sampled_subframes.append(pd.concat([sampled_test, sampled_other]))\n",
    "    else:\n",
    "        # If less than 256 rows in the group, append all rows\n",
    "        sampled_subframes.append(group)\n",
    "\n",
    "\n",
    "# Concatenate all sampled subframes row-wise into one DataFrame\n",
    "df_sampled = pd.concat(sampled_subframes, axis=0, ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "freq, counts = np.unique(df_sampled['class'], return_counts=True)\n",
    "\n",
    "# subet to exactly 10\n",
    "df_sampled_unique = df_sampled.drop_duplicates(subset='path')\n",
    "\n",
    "# Keep only the first 10,000 rows\n",
    "df_sampled = df_sampled_unique.head(10240)\n",
    "\n",
    "# store\n",
    "if save_10k_flag:\n",
    "    df_sampled.to_csv('./testset_10240/df_10240.csv', sep='|', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fb4f3809-8826-41ef-b4e0-d99a95a3ca27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240,\n",
       " 10240,\n",
       " (array(['Nature', 'arxiv', 'biorxiv', 'bmc', 'mdpi', 'medrxiv'],\n",
       "        dtype=object), array([ 959, 2068, 2068, 1634, 2068, 1443])),\n",
       " 10240,\n",
       " (array(['test', 'train', 'val'], dtype=object), array([2688, 6524, 1028])))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sampled), len(set(df_sampled['path'])), np.unique(df_sampled['publisher'], return_counts=True), len(set(df_sampled['path'])), np.unique(df_sampled['subset'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca85cf-3239-42ce-9d71-81a4acb64a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
