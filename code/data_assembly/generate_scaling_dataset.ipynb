{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb89c4d7-ace2-4037-b373-45d5f54a606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import uuid\n",
    "import pymupdf\n",
    "import zipfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from utils import remove_text_layer, simulated_scanned_effect, zip_files, text_scrambler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d531293a-f167-4767-959d-c2c76e029191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root (PDFs)\n",
    "p_root = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/joint')\n",
    "assert p_root.is_dir(), \"Root/source dir of pdfs does not exist\"\n",
    "\n",
    "# dst\n",
    "p_dst = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/strong_scaling/data/pdf')\n",
    "assert p_dst.is_dir(), \"Destination dir for pdfs does not exist\"\n",
    "\n",
    "# import df\n",
    "p_df = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/database/scaling_data/frames/df_mod_10240.csv')\n",
    "df_10240 = pd.read_csv(p_df, sep='|')\n",
    "\n",
    "# unmanipulated\n",
    "df_unmanipulated = df_10240[df_10240['manipulated']==0]\n",
    "\n",
    "# unmanipulated\n",
    "df_manip = df_10240[df_10240['manipulated']==1]\n",
    "\n",
    "# EDIT: SAMPLE HALF of un-manipulated PDFs -> 30% manipulation rate (15% no text, 15% OCR-ed text)\n",
    "\n",
    "# Import df\n",
    "p_df = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/database/scaling_data/frames/df_mod_10240.csv')\n",
    "df_10240 = pd.read_csv(p_df, sep='|')\n",
    "\n",
    "# Unmanipulated DataFrame\n",
    "df_unmanipulated = df_10240[df_10240['manipulated'] == 0]\n",
    "\n",
    "# Sample half of the rows randomly\n",
    "df_unmanip_sampled = df_unmanipulated.sample(frac=0.75, random_state=42)\n",
    "\n",
    "# Only take the first 3584 rows\n",
    "df_unmanip_sampled = df_unmanip_sampled.head(3584)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "833b8704-53f9-4c60-9f8e-c037e5158c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3584, 3584.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_unmanip_sampled), 10_240 * 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87fff609-6208-4447-814a-2d467a023299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unmanipulated = df_unmanip_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb16614-0533-4f8f-96ee-2b87bdb38f25",
   "metadata": {},
   "source": [
    "## Copy PDFs\n",
    "\n",
    "#### 1. 8704 un-manipulated\n",
    "Transfer in parallel \"as is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28bd1cb4-84d2-49e3-b1fc-aebc17eadb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 3584 PDFs in dst path\n"
     ]
    }
   ],
   "source": [
    "copy_UNmanipulated = True\n",
    "copy_ToBeManipulated = False\n",
    "\n",
    "# copy all not-to-be manipulated files directly to destination \n",
    "if copy_UNmanipulated:\n",
    "    # copy all these files from here into `p_dst`\n",
    "    all_UNmanipulated_pdf_file_paths = [(p_root / f) for f in df_unmanipulated['path'] if (p_root / f).is_file()]\n",
    "    \n",
    "    # Function to copy a single file\n",
    "    def copy_file(src):\n",
    "        dst = p_dst / src.name  # Destination path\n",
    "        shutil.copy2(src, dst)  # Copy with metadata\n",
    "    \n",
    "    # Use ThreadPoolExecutor to copy files in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.map(copy_file, all_UNmanipulated_pdf_file_paths)\n",
    "\n",
    "    # msg\n",
    "    print(f'Done. {len(os.listdir(p_dst))} PDFs in dst path')\n",
    "\n",
    "\n",
    "# to be manipulated: copy from `joint` path to local directory (before further post-processing)\n",
    "if copy_ToBeManipulated:\n",
    "    # copy all these files from here into `p_dst`\n",
    "    to_be_manipulated_pdf_file_paths = [(p_root / f) for f in df_manip['path'] if (p_root / f).is_file()]\n",
    "    \n",
    "    # Function to copy a single file\n",
    "    def copy_file(src):\n",
    "        dst = Path('./1536_original') / src.name  # Destination path\n",
    "        shutil.copy2(src, dst)  # Copy with metadata\n",
    "    \n",
    "    # Use ThreadPoolExecutor to copy files in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.map(copy_file, to_be_manipulated_pdf_file_paths)\n",
    "\n",
    "    # msg\n",
    "    print(f'Done. {len(os.listdir(p_dst))} PDFs in dst path {p_dst}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb28dd9-f8d1-4794-961d-c10fddd71bae",
   "metadata": {},
   "source": [
    "#### 2. 1536 manipulated \n",
    "Copy files one-by-one (post manipulation procedure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48084f2-340b-4ad8-ad94-28a4706d2707",
   "metadata": {},
   "source": [
    "# 3. Create ZIps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94fdae2d-18ee-4fcd-a409-debe7e99a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source & destination path\n",
    "p_pdf = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/strong_scaling/data/pdf/')\n",
    "p_zip = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/strong_scaling/data/zip/')\n",
    "\n",
    "# for logging\n",
    "zip_dict = {}\n",
    "\n",
    "# Function to zip files\n",
    "def zip_files(file_paths, output_zip_path):\n",
    "    with zipfile.ZipFile(output_zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file_path in file_paths:\n",
    "            # Add file to ZIP archive with its basename\n",
    "            zipf.write(file_path, arcname=Path(file_path).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4717e6-2891-41ba-8d1e-0b0ca8dfa026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing...\n",
      "Done w...\n",
      "Writing...\n",
      "Done w...\n",
      "Writing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:35\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mzip_files\u001b[0;34m(file_paths, output_zip_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(output_zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, compression\u001b[38;5;241m=\u001b[39mzipfile\u001b[38;5;241m.\u001b[39mZIP_DEFLATED) \u001b[38;5;28;01mas\u001b[39;00m zipf:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Add file to ZIP archive with its basename\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mzipf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/eagle/projects/tpc/siebenschuh/envs_/bo/lib/python3.11/zipfile.py:1814\u001b[0m, in \u001b[0;36mZipFile.write\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     zinfo\u001b[38;5;241m.\u001b[39m_compresslevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompresslevel\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/eagle/projects/tpc/siebenschuh/envs_/bo/lib/python3.11/shutil.py:200\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/eagle/projects/tpc/siebenschuh/envs_/bo/lib/python3.11/zipfile.py:1177\u001b[0m, in \u001b[0;36m_ZipWriteFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crc \u001b[38;5;241m=\u001b[39m crc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crc)\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor:\n\u001b[0;32m-> 1177\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#make this a program:(batch_size:int)\n",
    "\n",
    "# List of batch sizes\n",
    "#batch_sizes = [16, 64, 128]\n",
    "assert batch_size in batch_sizes, \"One of those batch sizes\"\n",
    "\n",
    "# source & destination path\n",
    "p_pdf = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/strong_scaling/data/pdf/')\n",
    "p_zip = Path('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/strong_scaling/data/zip/')\n",
    "\n",
    "# for logging\n",
    "zip_dict = {}\n",
    "\n",
    "# Function to zip files\n",
    "def zip_files(file_paths, output_zip_path):\n",
    "    with zipfile.ZipFile(output_zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file_path in file_paths:\n",
    "            # Add file to ZIP archive with its basename\n",
    "            zipf.write(file_path, arcname=Path(file_path).name)\n",
    "\n",
    "# Assuming p_zip is the base directory where the ZIPs will be stored\n",
    "# For example:\n",
    "p_zip.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Your list of PDF file paths (replace with your actual list)\n",
    "pdf_file_paths = list(Path(p_pdf).glob('*.pdf'))\n",
    "\n",
    "batch_size\n",
    "# Destination directory for this batch size\n",
    "p_dst = p_zip / f'b{batch_size}'\n",
    "p_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Split list into list of lists where each list has length `batch_size`\n",
    "# If the total number of PDFs is not a multiple of batch_size, the last list may be shorter\n",
    "list_of_lists = [\n",
    "    pdf_file_paths[i:i + batch_size]\n",
    "    for i in range(0, len(pdf_file_paths), batch_size)\n",
    "]\n",
    "\n",
    "# (no duplicates yet)\n",
    "for i, batch_file_paths in enumerate(list_of_lists):\n",
    "    # Generate random UUID string of length 10\n",
    "    # Construct the ZIP file name\n",
    "    zip_filename = (\n",
    "        f\"bs{str(batch_size).zfill(4)}\"\n",
    "        f\"id{str(i).zfill(3)}-{str(k).zfill(2)}.zip\"\n",
    "    )\n",
    "    # Output ZIP path\n",
    "    output_zip_path = p_dst / zip_filename\n",
    "    # Call zip_files function to create the ZIP file\n",
    "    print('Writing...')\n",
    "    zip_files(batch_file_paths, output_zip_path)\n",
    "    print('Done w...')\n",
    "    # Update the dictionary\n",
    "    zip_dict[str(output_zip_path)] = batch_file_paths\n",
    "\n",
    "# store\n",
    "# store zip_dict as f`zip_dict_{batchsize}.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb71cc4-26b7-4064-94e2-b903deb64420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/lus/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/strong_scaling/data/zip/b16/bs0016id005-00.zip')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dst / zip_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8ae2a-d5a8-47e5-94cc-4fce6cf765f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
